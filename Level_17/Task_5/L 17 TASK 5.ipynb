{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bdc0d8b-5d12-40f0-ae88-471abf562746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ipl_matches_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/FileStore/tables/ipl_2021_matches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd8c82e-59dd-4973-9902-c65ac41a150b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|year|num_teams|\n+----+---------+\n|2021|        1|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "teams_each_year = ipl_matches_df.select(\"year\", \"match_team1\", \"match_team2\") \\\n",
    "    .withColumn(\"team\", col(\"match_team1\")) \\\n",
    "    .union(\n",
    "        ipl_matches_df.select(\"year\", \"match_team1\", \"match_team2\")\n",
    "        .withColumn(\"team\", col(\"match_team2\"))\n",
    "    ) \\\n",
    "    .select(\"year\", \"team\") \\\n",
    "    .distinct() \\\n",
    "    .groupBy(\"year\").count().withColumnRenamed(\"count\", \"num_teams\")\n",
    "\n",
    "teams_each_year.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe956cc3-adb4-48cd-8ca0-52090a2b2e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: ['year',\n 'series_type',\n 'series_name',\n 'match_no',\n 'match_type',\n 'match_name',\n 'match_href',\n 'match_team1',\n 'match_team2',\n 'match_datetime_start',\n 'match_date_end',\n 'match_venue']"
     ]
    }
   ],
   "source": [
    "ipl_matches_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd685c1a-2313-4c4c-8119-886cb9f8666b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|match_type|count|\n+----------+-----+\n|    League|   62|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "ipl_matches_df.groupBy(\"match_type\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f72975-2d14-4867-9fff-bf8c830620bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+\n|match_id|inning|ball_no|\n+--------+------+-------+\n|      M1|     1|    1.1|\n|      M1|     1|    1.2|\n|      M1|     1|    2.1|\n|      M1|     2|    1.1|\n|      M1|     2|    1.2|\n|      M2|     1|    1.1|\n|      M2|     1|    1.2|\n|      M2|     1|    1.3|\n|      M2|     2|    1.1|\n|      M2|     2|    1.2|\n+--------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "sample_data = [\n",
    "    Row(match_id=\"M1\", inning=1, ball_no=1.1),\n",
    "    Row(match_id=\"M1\", inning=1, ball_no=1.2),\n",
    "    Row(match_id=\"M1\", inning=1, ball_no=2.1),\n",
    "    Row(match_id=\"M1\", inning=2, ball_no=1.1),\n",
    "    Row(match_id=\"M1\", inning=2, ball_no=1.2),\n",
    "    Row(match_id=\"M2\", inning=1, ball_no=1.1),\n",
    "    Row(match_id=\"M2\", inning=1, ball_no=1.2),\n",
    "    Row(match_id=\"M2\", inning=1, ball_no=1.3),\n",
    "    Row(match_id=\"M2\", inning=2, ball_no=1.1),\n",
    "    Row(match_id=\"M2\", inning=2, ball_no=1.2),\n",
    "]\n",
    "\n",
    "ball_df = spark.createDataFrame(sample_data)\n",
    "ball_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0656f668-ce74-4438-b12b-aa83c268d068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n|inning|avg_balls_per_match|\n+------+-------------------+\n|     1|                3.0|\n|     2|                2.0|\n+------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, avg\n",
    "\n",
    "balls_per_match_inning = ball_df.groupBy(\"match_id\", \"inning\") \\\n",
    "    .agg(count(\"ball_no\").alias(\"total_balls\"))\n",
    "\n",
    "avg_balls_per_inning = balls_per_match_inning.groupBy(\"inning\") \\\n",
    "    .agg(avg(\"total_balls\").alias(\"avg_balls_per_match\"))\n",
    "\n",
    "avg_balls_per_inning.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0808fc-d018-44b5-808c-931211bf360a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------+------+\n|year|match_team1|match_team2|winner|\n+----+-----------+-----------+------+\n|2021|         MI|        RCB|    MI|\n|2021|        CSK|        KKR|   CSK|\n|2022|         MI|        CSK|   CSK|\n|2022|        RCB|        KKR|   KKR|\n|2023|         GT|         RR|    GT|\n|2023|         MI|        RCB|   RCB|\n+----+-----------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "sample_matches = [\n",
    "    Row(year=2021, match_team1=\"MI\", match_team2=\"RCB\", winner=\"MI\"),\n",
    "    Row(year=2021, match_team1=\"CSK\", match_team2=\"KKR\", winner=\"CSK\"),\n",
    "    Row(year=2022, match_team1=\"MI\", match_team2=\"CSK\", winner=\"CSK\"),\n",
    "    Row(year=2022, match_team1=\"RCB\", match_team2=\"KKR\", winner=\"KKR\"),\n",
    "    Row(year=2023, match_team1=\"GT\", match_team2=\"RR\", winner=\"GT\"),\n",
    "    Row(year=2023, match_team1=\"MI\", match_team2=\"RCB\", winner=\"RCB\"),\n",
    "]\n",
    "\n",
    "matches_df = spark.createDataFrame(sample_matches)\n",
    "matches_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae415d8-c851-4434-8c00-c742cfaacb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----------+\n|year|winner|matches_won|\n+----+------+-----------+\n|2021|    MI|          1|\n|2021|   CSK|          1|\n|2022|   CSK|          1|\n|2022|   KKR|          1|\n|2023|    GT|          1|\n|2023|   RCB|          1|\n+----+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "team_wins_per_year = matches_df.groupBy(\"year\", \"winner\") \\\n",
    "    .count().withColumnRenamed(\"count\", \"matches_won\") \\\n",
    "    .orderBy(\"year\", col(\"matches_won\").desc())\n",
    "\n",
    "team_wins_per_year.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d836f98-70d0-4f3e-bd44-53ae74851e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------------+\n|match_id|batting_team|         batsman|\n+--------+------------+----------------+\n|      M1|          MI|    Rohit Sharma|\n|      M1|          MI|Suryakumar Yadav|\n|      M1|         RCB|     Virat Kohli|\n|      M1|         RCB|  AB de Villiers|\n|      M2|         CSK|        MS Dhoni|\n|      M2|         CSK| Ruturaj Gaikwad|\n|      M2|         KKR|    Shubman Gill|\n|      M2|         KKR|   Andre Russell|\n+--------+------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "sample_ball_data = [\n",
    "    Row(match_id=\"M1\", batting_team=\"MI\", batsman=\"Rohit Sharma\"),\n",
    "    Row(match_id=\"M1\", batting_team=\"MI\", batsman=\"Suryakumar Yadav\"),\n",
    "    Row(match_id=\"M1\", batting_team=\"RCB\", batsman=\"Virat Kohli\"),\n",
    "    Row(match_id=\"M1\", batting_team=\"RCB\", batsman=\"AB de Villiers\"),\n",
    "    Row(match_id=\"M2\", batting_team=\"CSK\", batsman=\"MS Dhoni\"),\n",
    "    Row(match_id=\"M2\", batting_team=\"CSK\", batsman=\"Ruturaj Gaikwad\"),\n",
    "    Row(match_id=\"M2\", batting_team=\"KKR\", batsman=\"Shubman Gill\"),\n",
    "    Row(match_id=\"M2\", batting_team=\"KKR\", batsman=\"Andre Russell\")\n",
    "]\n",
    "ball_df = spark.createDataFrame(sample_ball_data)\n",
    "ball_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f930e66b-3a46-41f8-af27-a379b805098f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------------------+--------------------------------+\n|match_id|batting_team|batsmen_list                    |batsmen_set                     |\n+--------+------------+--------------------------------+--------------------------------+\n|M1      |MI          |[Rohit Sharma, Suryakumar Yadav]|[Suryakumar Yadav, Rohit Sharma]|\n|M1      |RCB         |[Virat Kohli, AB de Villiers]   |[Virat Kohli, AB de Villiers]   |\n|M2      |CSK         |[MS Dhoni, Ruturaj Gaikwad]     |[MS Dhoni, Ruturaj Gaikwad]     |\n|M2      |KKR         |[Shubman Gill, Andre Russell]   |[Shubman Gill, Andre Russell]   |\n+--------+------------+--------------------------------+--------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "batsmen_comparison = ball_df.groupBy(\"match_id\", \"batting_team\") \\\n",
    "    .agg(\n",
    "        collect_list(\"batsman\").alias(\"batsmen_list\"),\n",
    "        collect_set(\"batsman\").alias(\"batsmen_set\")\n",
    "    )\n",
    "\n",
    "batsmen_comparison.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "L 17  TASK 5",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}